from more_itertools import unzip, duplicates_everseen
from functools import partial
from pathlib import Path
from snakemake.utils import min_version, validate
from scripts.common.config import all_feature_names, input_set, expand_rules

min_version("6.12")


configfile: "config/static.yml"


################################################################################
# Validation
#
# These functions are necessary to validate properties of the config file(s)
# that are not possible using JSON schema validation.
#
# In particular:
# - For each in 'ebm_runs', make sure there are no duplicated feature names
#   (especially considering that features can be renamed on-the-fly with
#   'alt_name' and make sure 'alt_name' features have the same prefix as
#   their parent feature name if they exist
# - For each in 'ebm_runs', make sure explicitly named interaction terms are
#   also in the feature set
# - Make sure input files in for each in 'ebm_runs' are in the 'inputs' section


# TODO make unittests for these
def validate_features(config):
    def assert_1(run_name, feature_list, feature):
        assert (
            feature in feature_list
        ), f"Interaction {feature} not found in feature set for run {run_name}"

    def assert_N(run_name, feature_list, ints):
        for i in ints:
            assert_1(run_name, feature_list, i)

    def flatten_features(fs):
        return [k if v["alt_name"] is None else v["alt_name"] for k, v in fs.items()]

    flat = [
        (k, ints, v["features"])
        for k, v in config["ebm_runs"].items()
        if "interactions" in v and isinstance(ints := v["interactions"], list)
    ]

    for run_name, ints, features in flat:
        # test that all feature names are valid
        valid_features = set(all_feature_names(config))
        fs = set(list(features))
        assert fs <= valid_features, "Invalid features: {}".format(
            ", ".join(fs - valid_features)
        )

        for k, v in features.items():
            # test feature alt names
            alt = v["alt_name"]
            if alt is not None:
                prefix = re.match("^[^_]+", k)[0]
                alt_prefix = re.match("^[^_]+", alt)[0]
                assert alt_prefix == prefix, f"Alt prefix must match for {k}"

            # test truncation values
            truncate = v["visualization"]["truncate"]
            tlower = truncate["lower"]
            tupper = truncate["upper"]
            if tlower is not None and tupper is not None:
                assert tlower < tupper, f"Non-positive truncation for {k}"

        # test duplicate alt names
        flat_feature_names = flatten_features(features)
        dups = [*duplicates_everseen(flat_feature_names)]
        assert len(dups) == 0, f"Duplicated features: {', '.join(dups)}"

        # test for matching interaction terms
        for i in ints:
            check = assert_N if isinstance(i, list) else assert_1
            check(run_name, flat_feature_names, i)


def validate_inputs(config):
    inputs = set(config["inputs"])
    for k, v in config["ebm_runs"].items():
        assert (
            set(j for i in v["inputs"] for j in i) <= inputs
        ), f"Run config {k} contains invalid input keys"


validate(config, "schemas/config-schema.yml")
validate_inputs(config)
validate_features(config)


################################################################################
# Paths

conf_paths = config["paths"]
resources_dir = Path(conf_paths["resources"])
results_dir = Path(conf_paths["results"])
_scripts_dir = Path("workflow/scripts")

# this is necessary as envs/scripts are apparently resolved locally in each rule
# file
def build_abs_path(relpath, basename):
    return str(relpath.resolve() / basename)


envs_path = partial(build_abs_path, Path("workflow/envs"))
scripts_path = partial(build_abs_path, _scripts_dir)
rmd_path = partial(build_abs_path, _scripts_dir / "rmarkdown")


################################################################################
# Import Subworkflows


include: "rules/labels/parse_vcf.smk"
include: "rules/annotations/get_annotations.smk"
include: "rules/train_ebm.smk"


################################################################################
# Main Target


rule all:
    input:
        rules.all_summary.input,
        rules.all_ebm.input,


################################################################################
# Testing Targets


rule all_resources:
    input:
        expand(rules.download_input_vcf.output, input_key=[*config["inputs"]]),
        expand(rules.download_ref_sdf.output, ref_key=input_set(config, "ref")),
        expand(
            expand_rules(
                rules,
                [
                    "download_bench_vcf",
                    "download_bench_bed",
                    "generate_bench_tbi",
                ],
                "output",
            ),
            bench_key=input_set(config, "benchmark"),
        ),
        # TODO all these implicitly depend on the reference
        rules.get_genome.output,
        rules.get_mappability_high_src.output,
        rules.get_mappability_low_src.output,
        rules.get_repeat_masker_src.output,
        rules.get_superdups_src.output,
        rules.get_simreps_src.output,
